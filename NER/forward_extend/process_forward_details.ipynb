{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T01:37:05.564168Z",
     "start_time": "2023-07-21T01:37:05.549037Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_details(file_path):\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        forward_details = f.readlines()\n",
    "\n",
    "\n",
    "    merged_list = []\n",
    "    current_item = \"\"\n",
    "\n",
    "    for i, item in enumerate(forward_details):\n",
    "        if item.strip() and item.strip()[0].isdigit():\n",
    "            j = 1\n",
    "            while j < len(item.strip()) and item.strip()[j].isdigit():\n",
    "                j += 1\n",
    "            if j < len(item.strip()) and item.strip()[j] == \"：\":\n",
    "                merged_list.append(current_item)\n",
    "                current_item = item.strip()\n",
    "            else:\n",
    "                current_item += item.strip()\n",
    "        else:\n",
    "            current_item += item.strip()\n",
    "\n",
    "    merged_list.append(current_item)\n",
    "    merged_list.pop(0)\n",
    "    return merged_list\n",
    "\n",
    "\n",
    "def get_extend_map(merged_list, mode):\n",
    "    entity_extend_map = {}\n",
    "    for i, item in enumerate(merged_list):\n",
    "        if mode == \"zh\":\n",
    "            item = item.replace(\" \",\"\")\n",
    "\n",
    "        golds = eval(item.split(\"gold:\")[1])\n",
    "        for gold in golds:\n",
    "            if gold not in entity_extend_map:\n",
    "                entity_extend_map[gold] = []\n",
    "\n",
    "\n",
    "        extend_ent_str = item.split(\"gold:\")[0]\n",
    "        matches = re.findall(r'\\[(.*?)\\]', extend_ent_str)\n",
    "\n",
    "        for match in matches:\n",
    "            if mode == \"zh\":\n",
    "                match = match.replace(\"，\",\",\").split(\",\")\n",
    "            elif mode == \"en\":\n",
    "                match = match.split(\",\")\n",
    "            elif \"zh\" in mode:\n",
    "                match = match.replace('\"','').replace('（','').replace('）','').replace('(','').replace(')','')\n",
    "                match = re.sub(r\"[\\[\\]']\", '', match.replace(\"，\",\",\")).split(\",\")\n",
    "            elif 'en' in mode:\n",
    "                match = match.replace('\"','').replace('（','').replace('）','').replace('(','').replace(')','')\n",
    "                match = re.sub(r\"[\\[\\]']\", '', match.replace(\"，\",\",\")).split(\",\")\n",
    "\n",
    "            if len(match) != len(golds):\n",
    "                continue\n",
    "            for idx, extend_ent in enumerate(match):\n",
    "                extend_ent = extend_ent.strip()\n",
    "                if extend_ent not in entity_extend_map[golds[idx]]:\n",
    "                    entity_extend_map[golds[idx]].append(extend_ent)\n",
    "\n",
    "    lengths = [len(entity_extend_map[key]) for key in entity_extend_map]\n",
    "\n",
    "    with open(f'./results/entity_extend_map_{mode}.json','w',encoding='utf-8') as f:\n",
    "        json.dump(entity_extend_map, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    return entity_extend_map, lengths\n",
    "\n",
    "\n",
    "def get_filtered_extend_map(entity_extend_map, mode):\n",
    "    if \"_zh\" in mode:\n",
    "        gold_type = ['药物','身体','医疗程序','临床表现','医疗设备','医学检验项目','科室','微生物类','疾病']\n",
    "    else:\n",
    "        gold_type = [\"organization\", \"person\", \"geographical social political\", \"vehicle\", \"location\", \"weapon\", \"facility\"]\n",
    "\n",
    "    \n",
    "    filtered_entity_extend_map = {}\n",
    "    for key in entity_extend_map:\n",
    "        filtered_entity_extend_map[key] = [item for item in entity_extend_map[key] if item not in gold_type]\n",
    "\n",
    "    filtered_lengths = [len(filtered_entity_extend_map[key]) for key in filtered_entity_extend_map]\n",
    "\n",
    "    with open(f'./results/filtered_entity_extend_map_{mode}.json','w',encoding='utf-8') as f:\n",
    "        json.dump(filtered_entity_extend_map, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return filtered_entity_extend_map, filtered_lengths\n",
    "\n",
    "\n",
    "\n",
    "def human_process(filtered_entity_extend_map, mode):\n",
    "    repeated_values = []\n",
    "    value_to_keys = {}\n",
    "\n",
    "\n",
    "    for key1, values1 in filtered_entity_extend_map.items():\n",
    "        for key2, values2 in filtered_entity_extend_map.items():\n",
    "            if key1 != key2 and key1 < key2:\n",
    "                for value in values1:\n",
    "                    if value in values2:\n",
    "                        repeated_values.append(value)\n",
    "                        if value in value_to_keys.keys():\n",
    "                            if key1 not in value_to_keys[value]:\n",
    "                                value_to_keys[value].append(key1)\n",
    "                            if key2 not in value_to_keys[value]:\n",
    "                                value_to_keys[value].append(key2)\n",
    "                        else:\n",
    "                            value_to_keys[value] = [key1, key2]\n",
    "\n",
    "    with open(f'./results/交集_{mode}_raw.txt','w',encoding='utf-8') as f:\n",
    "        for value, keys in value_to_keys.items():\n",
    "            f.write('{} ：{}\\n'.format(value, '、'.join(keys)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_map(mode):\n",
    "    with open(f'./results/filtered_entity_extend_map_{mode}.json','r',encoding='utf-8') as f:\n",
    "        filtered_entity_extend_map_zh = json.load(f)\n",
    "\n",
    "    with open(f'./results/交集_{mode}_raw.txt','r',encoding='utf-8') as f:\n",
    "        raw_zh = f.readlines()\n",
    "\n",
    "    tmp_dict1 = {item.split(' ：')[0].strip(): item.split(' ：')[1].strip().split('、') for item in raw_zh}\n",
    "    jiaoji_raw_dict = {value: [key for key, val in tmp_dict1.items() if value in val] for key, values in tmp_dict1.items() for value in values}\n",
    "\n",
    "    with open(f'./results/交集_{mode}.txt','r',encoding='utf-8') as f:\n",
    "        new_zh = f.readlines()\n",
    "\n",
    "    tmp_dict2 = {item.split(' ：')[0].strip(): item.split(' ：')[1].strip() for item in new_zh}\n",
    "    jiaoji_new_dict = {}\n",
    "    for key, value in tmp_dict2.items():\n",
    "        if value in jiaoji_new_dict:\n",
    "            jiaoji_new_dict[value].append(key)\n",
    "        else:\n",
    "            jiaoji_new_dict[value] = [key]\n",
    "\n",
    "    for key in filtered_entity_extend_map_zh.keys():\n",
    "        tmp_list = jiaoji_raw_dict[key]\n",
    "        wuguan_list = [value for value in filtered_entity_extend_map_zh[key] if value not in tmp_list]\n",
    "        ok_list = jiaoji_new_dict[key]\n",
    "        filtered_entity_extend_map_zh[key] = wuguan_list + ok_list\n",
    "\n",
    "    with open(f'./results/final_entity_extend_map_{mode}.json','w',encoding='utf-8') as f:\n",
    "        json.dump(filtered_entity_extend_map_zh, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process_details:\n",
    "    def __init__(self, file_path, mode):\n",
    "        self.file_path = file_path\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        merged_list = merge_details(self.file_path)\n",
    "        entity_extend_map, lengths = get_extend_map(merged_list, mode=self.mode)\n",
    "        filtered_entity_extend_map, filtered_lengths = get_filtered_extend_map(entity_extend_map, mode=self.mode)\n",
    "        human_process(filtered_entity_extend_map, mode=self.mode)\n",
    "\n",
    "        return lengths, filtered_lengths\n",
    "    \n",
    "    def post_process(self):\n",
    "        get_final_map(mode=self.mode)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_cmeee = Process_details('./results/extend_forward_zh.txt','zh')\n",
    "lengths, filtered_lengths = process_cmeee.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_ace05 = Process_details('./results/extend_forward_en.txt','en')\n",
    "lengths, filtered_lengths = process_ace05.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpaca-CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_alpaca_cmeee = Process_details('./results/extend_forward_alpaca_33B_zh.txt','alpaca_33B_zh')\n",
    "lengths, filtered_lengths = process_alpaca_cmeee.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpaca-ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_alpaca_ace05 = Process_details('./results/extend_forward_alpaca_33B_en.txt','alpaca_33B_en')\n",
    "lengths, filtered_lengths = process_alpaca_ace05.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama2-ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_llama2_ace05 = Process_details('./results/extend_forward_llama2_70B_en.txt','llama2_70B_en')\n",
    "lengths, filtered_lengths = process_llama2_ace05.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_chatglm_cmeee = Process_details('./results/extend_forward_chatglm_6B_zh.txt','chatglm_6B_zh')\n",
    "lengths, filtered_lengths = process_chatglm_cmeee.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_chatglm_ace05 = Process_details('./results/extend_forward_chatglm_6B_en.txt','chatglm_6B_en')\n",
    "lengths, filtered_lengths = process_chatglm_ace05.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4-CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_gpt4_cmeee = Process_details('./results/extend_forward_gpt4_zh.txt','gpt4_zh')\n",
    "lengths, filtered_lengths = process_gpt4_cmeee.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4-ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_gpt4_ace05 = Process_details('./results/extend_forward_gpt4_en.txt','gpt4_en')\n",
    "lengths, filtered_lengths = process_gpt4_ace05.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_baichuan2_cmeee = Process_details('./results/extend_forward_baichuan2_13B_zh.txt','baichuan2_13B_zh')\n",
    "lengths, filtered_lengths = process_baichuan2_cmeee.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_baichuan2_ace05 = Process_details('./results/extend_forward_baichuan2_13B_en.txt','baichuan2_13B_en')\n",
    "lengths, filtered_lengths = process_baichuan2_ace05.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_cmeee.post_process()\n",
    "# process_ace05.post_process()\n",
    "# process_alpaca_cmeee.post_process()\n",
    "# process_alpaca_ace05.post_process()\n",
    "# process_llama2_ace05.post_process()\n",
    "# process_chatglm_cmeee.post_process()\n",
    "# process_chatglm_ace05.post_process()\n",
    "process_baichuan2_cmeee.post_process()\n",
    "process_baichuan2_ace05.post_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
