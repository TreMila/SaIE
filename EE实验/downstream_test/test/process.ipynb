{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:11:56.776507Z",
     "start_time": "2023-12-11T07:11:56.762530Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:12:05.755485Z",
     "start_time": "2023-12-11T07:12:05.733419Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_details(details):\n",
    "    merged_list = []\n",
    "    current_item = \"\"\n",
    "\n",
    "    for i, item in enumerate(details):\n",
    "        if item.strip() and item.strip()[0].isdigit():\n",
    "            j = 1\n",
    "            while j < len(item.strip()) and item.strip()[j].isdigit():\n",
    "                j += 1\n",
    "            if j < len(item.strip()) and item.strip()[j] == \"：\":\n",
    "                merged_list.append(current_item)\n",
    "                current_item = item.strip()\n",
    "            else:\n",
    "                current_item += item.strip()\n",
    "        else:\n",
    "            current_item += item.strip()\n",
    "\n",
    "    merged_list.append(current_item)\n",
    "    merged_list.pop(0)\n",
    "    return merged_list\n",
    "\n",
    "\n",
    "def extract_tuples(string):\n",
    "    tuples = []\n",
    "    depth = 0\n",
    "    start = None\n",
    "    for i, char in enumerate(string):\n",
    "        if char == \"(\" or char == \"（\":\n",
    "            if depth == 0:\n",
    "                start = i\n",
    "            depth += 1\n",
    "        elif char == \")\" or char == \"）\":\n",
    "            depth -= 1\n",
    "            if depth == 0 and start is not None:\n",
    "                tuples.append(string[start+1:i])\n",
    "                start = None\n",
    "    return tuples\n",
    "\n",
    "\n",
    "def get_results(merged_list, input_list, eve_extend_map, mode):\n",
    "    eve_extend_index = 0\n",
    "    cur_eve_extend_list = []\n",
    "    A = []\n",
    "\n",
    "    for idx, item in enumerate(merged_list):\n",
    "        B = []\n",
    "        cur_output_3 = item.split('Output:')\n",
    "        cur_idx = cur_output_3[0].split('：')[0]\n",
    "        cur_true_eve = input_list[int(cur_idx)-1]['event_type']\n",
    "            \n",
    "        if eve_extend_index == len(cur_eve_extend_list):\n",
    "            eve_extend_index = 0\n",
    "\n",
    "        cur_eve_extend_list = eve_extend_map[cur_true_eve]\n",
    "        cur_extend_eve = cur_eve_extend_list[eve_extend_index]\n",
    "\n",
    "\n",
    "        for output in cur_output_3[1:]:\n",
    "            sep = \"\"\n",
    "            if 'zh' in mode:\n",
    "                if \"生成事件检测列表:\" in output:\n",
    "                    sep = \"生成事件检测列表:\"\n",
    "            elif 'en' in mode:\n",
    "                if \"Generate a list of event detections:\" in output:\n",
    "                    sep = \"Generate a list of event detections:\"\n",
    "                elif \"Generated event detection list:\" in output:\n",
    "                    sep = \"Generated event detection list:\"\n",
    "                elif \"Event detection list:\" in output:\n",
    "                    sep = \"Event detection list:\"\n",
    "                elif \"Event detections:\" in output:\n",
    "                    sep = \"Event detections:\"\n",
    "            if sep:\n",
    "                tmp = output.split(sep)[1]\n",
    "                matches = extract_tuples(tmp)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        if 'zh' in mode:\n",
    "                            triple = tuple(match.strip().strip('（）').split(','))\n",
    "                        elif 'en' in mode:\n",
    "                            triple = tuple(match.strip().strip('()').split(','))\n",
    "                        if len(triple) == 2:\n",
    "                            B.append((int(cur_idx)-1, cur_extend_eve, triple[1].strip()))\n",
    "                        else:\n",
    "                            B.append((int(cur_idx)-1, cur_extend_eve, ''))\n",
    "                else:\n",
    "                    B.append((int(cur_idx)-1, cur_extend_eve, ''))\n",
    "                \n",
    "            else:\n",
    "                B.append((int(cur_idx)-1, cur_extend_eve, ''))\n",
    "                continue\n",
    "        if B:\n",
    "            A.append(B)    \n",
    "\n",
    "        eve_extend_index += 1\n",
    "\n",
    "    A = [list(set(item)) for item in A]\n",
    "    \n",
    "    with open(f'./results/test_{mode}.txt','w',encoding='utf-8') as f:\n",
    "        for item in A:\n",
    "            f.write(str(item)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DuEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/duee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/duee/event_extend_map.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'zh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/casie/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/casie/event_extend_map.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-DuEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_chatglm_6B_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/duee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/duee/final_event_extend_map_chatglm_6B_zh.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'chatglm_6B_zh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-CASIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_chatglm_6B_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/casie/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/casie/final_event_extend_map_chatglm_6B_en.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'chatglm_6B_en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-DuEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:13:49.158494Z",
     "start_time": "2023-12-11T07:13:48.835857Z"
    }
   },
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_baichuan2_13B_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/duee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/duee/final_event_extend_map_baichuan2_13B_zh.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'baichuan2_13B_zh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-CASIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:14:06.592486Z",
     "start_time": "2023-12-11T07:14:06.373318Z"
    }
   },
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_baichuan2_13B_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/casie/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/casie/final_event_extend_map_baichuan2_13B_en.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'baichuan2_13B_en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_alpaca_33B_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/duee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/duee/final_event_extend_map_alpaca_33B_zh.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'alpaca_33B_zh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理反向验证的输出文件\n",
    "with open('./results/details_alpaca_33B_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/casie/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/casie/final_event_extend_map_alpaca_33B_en.json','r',encoding='utf-8') as f:\n",
    "    eve_extend_map = json.load(f)\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, eve_extend_map, 'alpaca_33B_en')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
