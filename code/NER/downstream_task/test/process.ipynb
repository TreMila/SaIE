{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T09:02:13.803424Z",
     "start_time": "2023-12-11T09:02:13.788941Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T09:02:19.300728Z",
     "start_time": "2023-12-11T09:02:19.276739Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_details(details):\n",
    "    merged_list = []\n",
    "    current_item = \"\"\n",
    "\n",
    "    for i, item in enumerate(details):\n",
    "        if item.strip() and item.strip()[0].isdigit():\n",
    "            j = 1\n",
    "            while j < len(item.strip()) and item.strip()[j].isdigit():\n",
    "                j += 1\n",
    "            if j < len(item.strip()) and item.strip()[j] == \"：\":\n",
    "                merged_list.append(current_item)\n",
    "                current_item = item.strip()\n",
    "            else:\n",
    "                current_item += item.strip()\n",
    "        else:\n",
    "            current_item += item.strip()\n",
    "\n",
    "    merged_list.append(current_item)\n",
    "    merged_list.pop(0)\n",
    "    return merged_list\n",
    "\n",
    "\n",
    "def extract_tuples(string):\n",
    "    tuples = []\n",
    "    depth = 0\n",
    "    start = None\n",
    "    for i, char in enumerate(string):\n",
    "        if char == \"(\" or char == \"（\":\n",
    "            if depth == 0:\n",
    "                start = i\n",
    "            depth += 1\n",
    "        elif char == \")\" or char == \"）\":\n",
    "            depth -= 1\n",
    "            if depth == 0 and start is not None:\n",
    "                tuples.append(string[start+1:i])\n",
    "                start = None\n",
    "    return tuples\n",
    "\n",
    "\n",
    "def get_results(merged_list, input_list, entity_type_dict, ent_extend_map, mode):\n",
    "    # input_list2ent = {}\n",
    "    # for idx, item in enumerate(input_list):\n",
    "    #     input_list2ent[item] = entity_type_list[idx//10]\n",
    "\n",
    "    ent_extend_index = 0\n",
    "    cur_ent_extend_list = []\n",
    "    A = []\n",
    "\n",
    "    for idx, item in enumerate(merged_list):\n",
    "        B = []\n",
    "        if 'en' in mode and \"``Text : \" in item:\n",
    "            item = item.split(\"``Text : \")[0]\n",
    "        cur_output_3 = item.split('Output:')\n",
    "        \n",
    "        cur_idx = cur_output_3[0].split('：')[0]\n",
    "        # cur_example = input_list[int(cur_idx)-1]\n",
    "        # cur_true_ent = input_list2ent[cur_example]\n",
    "        if 'zh' in mode:\n",
    "            cur_true_ent = entity_type_dict[input_list[int(cur_idx)-1]['ent_type']]\n",
    "        elif 'en' in mode:\n",
    "            cur_true_ent = input_list[int(cur_idx)-1]['ent_type']\n",
    "            \n",
    "        if ent_extend_index == len(cur_ent_extend_list):\n",
    "            ent_extend_index = 0\n",
    "\n",
    "        cur_ent_extend_list = ent_extend_map[cur_true_ent]\n",
    "        cur_extend_ent = cur_ent_extend_list[ent_extend_index]\n",
    "\n",
    "        for output in cur_output_3[1:]:\n",
    "            sep = \"\"\n",
    "            if 'zh' in mode:\n",
    "                if \"生成实体列表：\" in output:\n",
    "                    sep = \"生成实体列表：\"\n",
    "            elif 'en' in mode:\n",
    "                \n",
    "                if \"Entity list:\" in output:\n",
    "                    sep = \"Entity list:\"\n",
    "                elif \"Generate an entity list:\" in output:\n",
    "                    sep = \"Generate an entity list:\"\n",
    "                elif \"Generated entity list:\" in output:\n",
    "                    sep = \"Generated entity list:\"\n",
    "            if sep:\n",
    "                tmp = output.split(sep)[1]\n",
    "                matches = extract_tuples(tmp)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        if 'zh' in mode:\n",
    "                            triple = tuple(match.strip().strip('（）').split(','))\n",
    "                        elif 'en' in mode:\n",
    "                            triple = tuple(match.strip().strip('()').split(','))\n",
    "                        if len(triple) == 2:\n",
    "                            B.append((int(cur_idx)-1, cur_extend_ent, triple[1].strip()))\n",
    "                        else:\n",
    "                            B.append((int(cur_idx)-1, cur_extend_ent, ''))\n",
    "                else:\n",
    "                    B.append((int(cur_idx)-1, cur_extend_ent, ''))\n",
    "                \n",
    "            else:\n",
    "                B.append((int(cur_idx)-1, cur_extend_ent, ''))\n",
    "                continue\n",
    "        if B:\n",
    "            A.append(B)    \n",
    "\n",
    "        ent_extend_index += 1\n",
    "\n",
    "    A = [list(set(item)) for item in A]\n",
    "    \n",
    "    with open(f'./results/test_{mode}.txt','w',encoding='utf-8') as f:\n",
    "        for item in A:\n",
    "            f.write(str(item)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/cmeee/ent_extend_map.json','r',encoding='utf-8') as f:\n",
    "    ent_extend_map = json.load(f)\n",
    "\n",
    "entity_type_dict = {\n",
    "            'dru':'药物',\n",
    "            'bod':'身体',\n",
    "            'pro':'医疗程序',\n",
    "            'sym':'临床表现',\n",
    "            'equ':'医疗设备',\n",
    "            'ite':'医学检验项目',\n",
    "            'dep':'科室',\n",
    "            'mic':'微生物类',\n",
    "            'dis':'疾病'\n",
    "}\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, entity_type_dict, ent_extend_map, 'zh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/ace05/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/ace05/ent_extend_map.json','r',encoding='utf-8') as f:\n",
    "    ent_extend_map = json.load(f)\n",
    "\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, None, ent_extend_map, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-CMeEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_baichuan2_13B_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/cmeee/final_entity_extend_map_baichuan2_13B_zh.json','r',encoding='utf-8') as f:\n",
    "    ent_extend_map = json.load(f)\n",
    "\n",
    "# entity_type_list = ['dru', 'bod', 'pro', 'sym', 'equ', 'ite', 'dep', 'mic', 'dis']\n",
    "entity_type_dict = {\n",
    "            'dru':'药物',\n",
    "            'bod':'身体',\n",
    "            'pro':'医疗程序',\n",
    "            'sym':'临床表现',\n",
    "            'equ':'医疗设备',\n",
    "            'ite':'医学检验项目',\n",
    "            'dep':'科室',\n",
    "            'mic':'微生物类',\n",
    "            'dis':'疾病'\n",
    "}\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, entity_type_dict, ent_extend_map, 'baichuan2_13B_zh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-ACE05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T09:02:29.975864Z",
     "start_time": "2023-12-11T09:02:29.811900Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./results/details_baichuan2_13B_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/ace05/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/ace05/final_entity_extend_map_baichuan2_13B_en.json','r',encoding='utf-8') as f:\n",
    "    ent_extend_map = json.load(f)\n",
    "\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, None, ent_extend_map, 'baichuan2_13B_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_alpaca_33B_zh.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeee/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/cmeee/final_entity_extend_map_alpaca_33B_zh.json','r',encoding='utf-8') as f:\n",
    "    ent_extend_map = json.load(f)\n",
    "\n",
    "# entity_type_list = ['dru', 'bod', 'pro', 'sym', 'equ', 'ite', 'dep', 'mic', 'dis']\n",
    "entity_type_dict = {\n",
    "            'dru':'药物',\n",
    "            'bod':'身体',\n",
    "            'pro':'医疗程序',\n",
    "            'sym':'临床表现',\n",
    "            'equ':'医疗设备',\n",
    "            'ite':'医学检验项目',\n",
    "            'dep':'科室',\n",
    "            'mic':'微生物类',\n",
    "            'dis':'疾病'\n",
    "}\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, entity_type_dict, ent_extend_map, 'alpaca_33B_zh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_alpaca_33B_en.txt','r',encoding='utf-8') as f:\n",
    "    test_details = f.readlines()\n",
    "\n",
    "with open('./data/ace05/input_list.json','r',encoding='utf-8') as f:\n",
    "    input_list = json.load(f)\n",
    "\n",
    "with open('./data/ace05/final_entity_extend_map_alpaca_33B_en.json','r',encoding='utf-8') as f:\n",
    "    ent_extend_map = json.load(f)\n",
    "\n",
    "\n",
    "merged_list = merge_details(test_details)\n",
    "get_results(merged_list, input_list, None, ent_extend_map, 'alpaca_33B_en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
