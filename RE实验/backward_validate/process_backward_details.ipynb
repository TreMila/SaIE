{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_details(backward_details):\n",
    "    merged_list = []\n",
    "    current_item = \"\"\n",
    "\n",
    "    for i, item in enumerate(backward_details):\n",
    "        if item.strip() and item.strip()[0].isdigit():\n",
    "            j = 1\n",
    "            while j < len(item.strip()) and item.strip()[j].isdigit():\n",
    "                j += 1\n",
    "            if j < len(item.strip()) and item.strip()[j] == \"：\":\n",
    "                merged_list.append(current_item)\n",
    "                current_item = item.strip()\n",
    "            else:\n",
    "                current_item += item.strip()\n",
    "        else:\n",
    "            current_item += item.strip()\n",
    "\n",
    "    merged_list.append(current_item)\n",
    "    merged_list.pop(0)\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tuples(string):\n",
    "    tuples = []\n",
    "    depth = 0\n",
    "    start = None\n",
    "    for i, char in enumerate(string):\n",
    "        if char == \"(\" or char == '（' or char == '[':\n",
    "            if depth == 0:\n",
    "                start = i\n",
    "            depth += 1\n",
    "        elif char == \")\" or char == '）' or char == ']':\n",
    "            depth -= 1\n",
    "            if depth == 0 and start is not None:\n",
    "                tuples.append(string[start+1:i])\n",
    "                start = None\n",
    "    return tuples\n",
    "\n",
    "def get_results(merged_list, input_list, rel_type_list, rel_extend_map, mode):\n",
    "    input_list2rel = {}\n",
    "    for idx, item in enumerate(input_list):\n",
    "        input_list2rel[item] = rel_type_list[idx//10]\n",
    "\n",
    "    rel_extend_index = 0\n",
    "    cur_rel_extend_list = []\n",
    "    A = []\n",
    "\n",
    "    for idx, item in enumerate(merged_list):\n",
    "        B = []\n",
    "        cur_output_3 = item.split('Output:')\n",
    "        cur_idx = cur_output_3[0].split('：')[0]\n",
    "        cur_example = input_list[int(cur_idx)-1]\n",
    "        cur_true_rel = input_list2rel[cur_example]\n",
    "\n",
    "        if rel_extend_index == len(cur_rel_extend_list):\n",
    "            rel_extend_index = 0\n",
    "\n",
    "        cur_rel_extend_list = rel_extend_map[cur_true_rel]\n",
    "        if not cur_rel_extend_list:\n",
    "            continue\n",
    "        try:\n",
    "            cur_extend_rel = cur_rel_extend_list[rel_extend_index]\n",
    "        except:\n",
    "            print(idx, cur_true_rel)\n",
    "\n",
    "        for output in cur_output_3[1:]:\n",
    "            sep = \"\"\n",
    "            if 'zh' in mode:\n",
    "                if \"生成关系列表：\" in output:\n",
    "                    sep = \"生成关系列表：\"\n",
    "                elif \"生成关系列表:\" in output:\n",
    "                    sep = \"生成关系列表:\"\n",
    "                elif \"生成关系列表为：\" in output:\n",
    "                    sep = \"生成关系列表为：\"\n",
    "                elif \"生成的关系列表为：\" in output:\n",
    "                    sep = \"生成的关系列表为：\"\n",
    "            elif 'en' in mode:\n",
    "                if \"Generated list of relations:\" in output:\n",
    "                    sep = \"Generated list of relations:\"\n",
    "                elif \"Generate a list of relations:\" in output:\n",
    "                    sep = \"Generate a list of relations:\"\n",
    "                elif \"List of Relations:\" in output:\n",
    "                    sep = \"List of Relations:\"\n",
    "                elif \"relation list:\" in output:\n",
    "                    sep = \"relation list:\"\n",
    "                elif \"Generate a list of relationships:\" in output:\n",
    "                    sep = \"Generate a list of relationships:\"\n",
    "                elif \"generate relationship list:\" in output:\n",
    "                    sep = \"generate relationship list:\"\n",
    "                \n",
    "            if sep:\n",
    "                tmp = output.split(sep)[1]\n",
    "                matches = extract_tuples(tmp)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        if 'zh' in mode:\n",
    "                            triple = tuple(match.replace('，',',').strip().strip('（）').split(','))\n",
    "                        elif 'en' in mode:\n",
    "                            triple = tuple(match.strip().strip('()').split(','))\n",
    "                        if len(triple) == 3: \n",
    "                            if 'zh' in mode:\n",
    "                                if cur_extend_rel == triple[0].strip().strip('()').strip('\"\"'):\n",
    "                                    B.append((int(cur_idx)-1, cur_extend_rel, triple[1].strip().strip('()'), triple[2].strip().strip('()')))\n",
    "                                elif cur_extend_rel == triple[1].strip().strip('()').strip('\"\"'):\n",
    "                                    B.append((int(cur_idx)-1, cur_extend_rel, triple[0].strip().strip('()'), triple[2].strip().strip('()')))\n",
    "                                else:\n",
    "                                    B.append((int(cur_idx)-1, cur_extend_rel, '', ''))\n",
    "                            elif 'en' in mode:\n",
    "                                if sep != \"subject-object pair:\" and sep!=\"Subject-object pair:\":\n",
    "                                    B.append((int(cur_idx)-1, cur_extend_rel, triple[0].strip().strip('()'), triple[2].strip().strip('()')))\n",
    "                                else:\n",
    "                                    B.append((int(cur_idx)-1, cur_extend_rel, '', ''))\n",
    "                        elif len(triple) == 2:\n",
    "                            if sep == \"subject-object pair:\" or sep == \"Subject-object pair:\":\n",
    "                                B.append((int(cur_idx)-1, cur_extend_rel, triple[0].strip().strip('()'), triple[1].strip().strip('()')))\n",
    "                            else:\n",
    "                                B.append((int(cur_idx)-1, cur_extend_rel, '', ''))\n",
    "                        else:\n",
    "                            B.append((int(cur_idx)-1, cur_extend_rel, '', ''))\n",
    "\n",
    "                else:\n",
    "                    B.append((int(cur_idx)-1, cur_extend_rel, '', ''))\n",
    "                \n",
    "            else:\n",
    "                B.append((int(cur_idx)-1, cur_extend_rel, '', ''))\n",
    "                continue\n",
    "        if B:\n",
    "            A.append(B)    \n",
    "\n",
    "        rel_extend_index += 1\n",
    "\n",
    "    A = [list(set(item)) for item in A]\n",
    "    \n",
    "    with open(f'./results/backward_{mode}.txt','w',encoding='utf-8') as f:\n",
    "        for item in A:\n",
    "            f.write(str(item)+'\\n')\n",
    "\n",
    "\n",
    "def get_gold_results(merged_list, input_list, rel_type_list, mode):\n",
    "    input_list2rel = {}\n",
    "    for idx, item in enumerate(input_list):\n",
    "        input_list2rel[item] = rel_type_list[idx//10]\n",
    "\n",
    "    A = []\n",
    "\n",
    "    for idx, item in enumerate(merged_list):\n",
    "        B = []\n",
    "        cur_output_3 = item.split('Output:')\n",
    "        cur_idx = cur_output_3[0].split('：')[0]\n",
    "        cur_example = input_list[int(cur_idx)-1]\n",
    "        cur_true_rel = input_list2rel[cur_example]\n",
    "\n",
    "\n",
    "        for output in cur_output_3[1:]:\n",
    "            sep = \"\"\n",
    "            if 'zh' in mode:\n",
    "                if \"生成关系列表：\" in output:\n",
    "                    sep = \"生成关系列表：\"\n",
    "                elif \"生成关系列表:\" in output:\n",
    "                    sep = \"生成关系列表:\"\n",
    "                elif \"生成关系列表为：\" in output:\n",
    "                    sep = \"生成关系列表为：\"\n",
    "                elif \"生成的关系列表为：\" in output:\n",
    "                    sep = \"生成的关系列表为：\"\n",
    "            elif 'en' in mode:\n",
    "                if \"Generated list of relations:\" in output:\n",
    "                    sep = \"Generated list of relations:\"\n",
    "                elif \"Generate a list of relations:\" in output:\n",
    "                    sep = \"Generate a list of relations:\"\n",
    "                elif \"List of Relations:\" in output:\n",
    "                    sep = \"List of Relations:\"\n",
    "                elif \"relation list:\" in output:\n",
    "                    sep = \"relation list:\"\n",
    "                elif \"Generate a list of relationships:\" in output:\n",
    "                    sep = \"Generate a list of relationships:\"\n",
    "                elif \"generate relationship list:\" in output:\n",
    "                    sep = \"generate relationship list:\"\n",
    "                \n",
    "            if sep:\n",
    "                tmp = output.split(sep)[1]\n",
    "                matches = extract_tuples(tmp)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        if 'zh' in mode:\n",
    "                            triple = tuple(match.strip().replace('，',',').strip('（）').split(','))\n",
    "                        elif 'en' in mode:\n",
    "                            triple = tuple(match.strip().strip('()').split(','))\n",
    "                        if len(triple) == 3 and sep != \"subject-object pair: \":\n",
    "                            B.append((int(cur_idx)-1, cur_true_rel, triple[0].strip().strip('()'), triple[2].strip().strip('()')))\n",
    "                        elif len(triple) == 2 and sep == \"subject-object pair: \":\n",
    "                            B.append((int(cur_idx)-1, cur_true_rel, triple[0].strip().strip('()'), triple[1].strip().strip('()')))\n",
    "                        else:\n",
    "                            B.append((int(cur_idx)-1, cur_true_rel, '', ''))\n",
    "                else:\n",
    "                    B.append((int(cur_idx)-1, cur_true_rel, '', ''))\n",
    "                \n",
    "            else:\n",
    "                B.append((int(cur_idx)-1, cur_true_rel, '', ''))\n",
    "                continue\n",
    "        if B:\n",
    "            A.append(B)    \n",
    "\n",
    "    A = [list(set(item)) for item in A]\n",
    "    \n",
    "    with open(f'./results/backward_gold_{mode}.txt','w',encoding='utf-8') as f:\n",
    "        for item in A:\n",
    "            f.write(str(item)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMeIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeie/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/cmeie/final_rel_extend_map_zh.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "# merged_list = merge_details(backward_details)\n",
    "# get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'zh')\n",
    "\n",
    "merged_list = merge_details(backward_gold_details)\n",
    "get_gold_results(merged_list, input_list, rel_type_list, 'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCIERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/scierc/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/scierc/final_rel_extend_map_en.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "merged_list = merge_details(backward_details)\n",
    "get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'en')\n",
    "# merged_list = merge_details(backward_gold_details)\n",
    "# get_gold_results(merged_list, input_list, rel_type_list, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpaca-CMeIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_alpaca_33B_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_alpaca_33B_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeie/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/cmeie/final_rel_extend_map_alpaca_33B_zh.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "# merged_list = merge_details(backward_details)\n",
    "# get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'alpaca_33B_zh')\n",
    "\n",
    "merged_list = merge_details(backward_gold_details)\n",
    "get_gold_results(merged_list, input_list, rel_type_list, 'alpaca_33B_zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpaca-SCIERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_alpaca_33B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_alpaca_33B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/scierc/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/scierc/final_rel_extend_map_alpaca_33B_en.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "merged_list = merge_details(backward_details)\n",
    "get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'alpaca_33B_en')\n",
    "\n",
    "# merged_list = merge_details(backward_gold_details)\n",
    "# get_gold_results(merged_list, input_list, rel_type_list, 'alpaca_33B_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama2-SCIERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_llama2_70B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_llama2_70B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/scierc/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/scierc/final_rel_extend_map_llama2_70B_en.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "# merged_list = merge_details(backward_details)\n",
    "# get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'llama2_70B_en')\n",
    "\n",
    "merged_list = merge_details(backward_gold_details)\n",
    "get_gold_results(merged_list, input_list, rel_type_list, 'llama2_70B_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-CMeIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_chatglm_6B_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_chatglm_6B_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeie/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/cmeie/final_rel_extend_map_chatglm_6B_zh.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "# merged_list = merge_details(backward_details)\n",
    "# get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'chatglm_6B_zh')\n",
    "\n",
    "merged_list = merge_details(backward_gold_details)\n",
    "get_gold_results(merged_list, input_list, rel_type_list, 'chatglm_6B_zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-SCIERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_chatglm_6B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_chatglm_6B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/scierc/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/scierc/final_rel_extend_map_chatglm_6B_en.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "merged_list = merge_details(backward_details)\n",
    "get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'chatglm_6B_en')\n",
    "\n",
    "# merged_list = merge_details(backward_gold_details)\n",
    "# get_gold_results(merged_list, input_list, rel_type_list, 'chatglm_6B_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4-CMeIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_gpt4_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeie/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/cmeie/final_rel_extend_map_gpt4_zh.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "merged_list = merge_details(backward_details)\n",
    "get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'gpt4_zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4-SCIERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_gpt4_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./data/scierc/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/scierc/final_rel_extend_map_gpt4_en.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "merged_list = merge_details(backward_details)\n",
    "get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'gpt4_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-CMeIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_baichuan2_13B_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_baichuan2_13B_zh.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/cmeie/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/cmeie/final_rel_extend_map_baichuan2_13B_zh.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "merged_list = merge_details(backward_details)\n",
    "get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'baichuan2_13B_zh')\n",
    "\n",
    "# merged_list = merge_details(backward_gold_details)\n",
    "# get_gold_results(merged_list, input_list, rel_type_list, 'baichuan2_13B_zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baichuan2-SCIERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/details_baichuan2_13B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_details = f.readlines()\n",
    "\n",
    "with open('./results/details_gold_baichuan2_13B_en.txt','r',encoding='utf-8') as f:\n",
    "    backward_gold_details = f.readlines()\n",
    "\n",
    "with open('./data/scierc/input_list.txt','r',encoding='utf-8') as f:\n",
    "    input_list = [item.strip() for item in f.readlines()]\n",
    "\n",
    "with open('./data/scierc/final_rel_extend_map_baichuan2_13B_en.json','r',encoding='utf-8') as f:\n",
    "    rel_extend_map = json.load(f)\n",
    "\n",
    "rel_type_list = list(rel_extend_map.keys())\n",
    "\n",
    "# merged_list = merge_details(backward_details)\n",
    "# get_results(merged_list, input_list, rel_type_list, rel_extend_map, 'baichuan2_13B_en')\n",
    "\n",
    "merged_list = merge_details(backward_gold_details)\n",
    "get_gold_results(merged_list, input_list, rel_type_list, 'baichuan2_13B_en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
